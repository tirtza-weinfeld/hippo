{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Training Analysis\n",
    "\n",
    "Visualize and understand what happens during neural network training.\n",
    "\n",
    "This notebook analyzes training logs created by `LoggedNeuralNetwork`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count":null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most recent log file\n",
    "log_dir = Path('../logs')\n",
    "log_files = sorted(log_dir.glob('training_*.jsonl'))\n",
    "\n",
    "if not log_files:\n",
    "    print(\"‚ùå No training logs found. Run a training session first!\")\n",
    "else:\n",
    "    log_file = log_files[-1]  # Most recent\n",
    "    print(f\"üìÇ Loading: {log_file.name}\")\n",
    "    \n",
    "    # Load all log entries\n",
    "    logs = []\n",
    "    with log_file.open() as f:\n",
    "        for line in f:\n",
    "            logs.append(json.loads(line))\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(logs)} log entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training Progress: Accuracy Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract epoch end metrics\n",
    "epoch_logs = [log for log in logs if log['type'] == 'epoch_end']\n",
    "\n",
    "epochs = [log['epoch'] for log in epoch_logs]\n",
    "accuracies = [log.get('accuracy_percent') for log in epoch_logs]\n",
    "\n",
    "# Plot accuracy progression\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, accuracies, marker='o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.title('Network Accuracy During Training', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight improvement\n",
    "if accuracies:\n",
    "    improvement = accuracies[-1] - accuracies[0]\n",
    "    plt.text(0.02, 0.98, f'Initial: {accuracies[0]:.1f}%\\nFinal: {accuracies[-1]:.1f}%\\nImprovement: +{improvement:.1f}%',\n",
    "             transform=plt.gca().transAxes, fontsize=10, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Weight Evolution: How Weights Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract weight snapshots\n",
    "weight_logs = [log for log in logs if log['type'] == 'weight_snapshot']\n",
    "\n",
    "# Track weight statistics per layer over time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Weight Evolution During Training', fontsize=16, fontweight='bold')\n",
    "\n",
    "if weight_logs:\n",
    "    num_layers = len(weight_logs[0]['layers'])\n",
    "    \n",
    "    for layer_idx in range(min(num_layers, 2)):  # Show first 2 layers\n",
    "        epochs_w = [log['epoch'] for log in weight_logs]\n",
    "        \n",
    "        # Weight mean\n",
    "        weight_means = [log['layers'][layer_idx]['weight_mean'] for log in weight_logs]\n",
    "        axes[layer_idx, 0].plot(epochs_w, weight_means, linewidth=2)\n",
    "        axes[layer_idx, 0].set_title(f'Layer {layer_idx} - Weight Mean')\n",
    "        axes[layer_idx, 0].set_xlabel('Epoch')\n",
    "        axes[layer_idx, 0].set_ylabel('Mean Value')\n",
    "        axes[layer_idx, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Weight std\n",
    "        weight_stds = [log['layers'][layer_idx]['weight_std'] for log in weight_logs]\n",
    "        axes[layer_idx, 1].plot(epochs_w, weight_stds, linewidth=2, color='orange')\n",
    "        axes[layer_idx, 1].set_title(f'Layer {layer_idx} - Weight Std Dev')\n",
    "        axes[layer_idx, 1].set_xlabel('Epoch')\n",
    "        axes[layer_idx, 1].set_ylabel('Std Deviation')\n",
    "        axes[layer_idx, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient Magnitudes: Learning Rate Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mini-batch logs\n",
    "batch_logs = [log for log in logs if log['type'] == 'mini_batch']\n",
    "\n",
    "if batch_logs:\n",
    "    # Group by epoch\n",
    "    epochs_unique = sorted(set(log['epoch'] for log in batch_logs))\n",
    "    \n",
    "    # Average gradient magnitude per epoch\n",
    "    grad_by_epoch = {}\n",
    "    for epoch in epochs_unique:\n",
    "        epoch_batches = [log for log in batch_logs if log['epoch'] == epoch]\n",
    "        avg_weight_grad = np.mean([np.mean(log['gradient_stats']['weight_mean']) for log in epoch_batches])\n",
    "        grad_by_epoch[epoch] = avg_weight_grad\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(list(grad_by_epoch.keys()), list(grad_by_epoch.values()), \n",
    "             marker='o', linewidth=2, markersize=8, color='green')\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Average Gradient Magnitude', fontsize=12)\n",
    "    plt.title('How Much Weights Changed Each Epoch', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üí° Large gradients = big changes, small gradients = fine-tuning\")\n",
    "else:\n",
    "    print(\"No gradient data logged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if epoch_logs:\n",
    "    durations = [log['duration_seconds'] for log in epoch_logs]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Time per epoch\n",
    "    ax1.bar(epochs, durations, color='steelblue', alpha=0.7)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Duration (seconds)')\n",
    "    ax1.set_title('Time Per Epoch')\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Distribution\n",
    "    ax2.hist(durations, bins=10, color='coral', alpha=0.7, edgecolor='black')\n",
    "    ax2.axvline(np.mean(durations), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(durations):.1f}s')\n",
    "    ax2.set_xlabel('Duration (seconds)')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.set_title('Epoch Duration Distribution')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    total_time = sum(durations)\n",
    "    print(f\"‚è±Ô∏è  Total training time: {total_time:.1f} seconds ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"üìä Average per epoch: {np.mean(durations):.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_log = [log for log in logs if log['type'] == 'training_complete']\n",
    "\n",
    "if completion_log and epoch_logs:\n",
    "    print(\"‚ïê\" * 50)\n",
    "    print(\"üìã TRAINING SUMMARY\")\n",
    "    print(\"‚ïê\" * 50)\n",
    "    print(f\"Session ID: {completion_log[0]['session_id']}\")\n",
    "    print(f\"Total Epochs: {len(epoch_logs)}\")\n",
    "    print(f\"Total Duration: {completion_log[0]['total_duration_seconds']:.1f}s\")\n",
    "    print()\n",
    "    print(f\"Initial Accuracy: {accuracies[0]:.2f}%\")\n",
    "    print(f\"Final Accuracy: {accuracies[-1]:.2f}%\")\n",
    "    print(f\"Best Accuracy: {max(accuracies):.2f}%\")\n",
    "    print(f\"Improvement: +{accuracies[-1] - accuracies[0]:.2f}%\")\n",
    "    print(\"‚ïê\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Custom Analysis\n",
    "\n",
    "Explore the logs yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available log types\n",
    "log_types = set(log['type'] for log in logs)\n",
    "print(\"Available log types:\", log_types)\n",
    "\n",
    "# Example: Look at first epoch_end log\n",
    "first_epoch = [log for log in logs if log['type'] == 'epoch_end'][0]\n",
    "print(\"\\nFirst epoch data:\")\n",
    "print(json.dumps(first_epoch, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
